{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt1H5o-poBfF"
   },
   "source": [
    "# 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU사용, 하이퍼파라미터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1X8mpttn-Vi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    " \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "print(device + \" is available\")\n",
    " \n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWzCD1LRn-vT"
   },
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader : 데이터를 불러 들어와서 옵션에 맞게 batchsize로 슬라이싱 해 mini-batchs로 만들어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YfkyOQioSBj"
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() \n",
    "    ])\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ_MTPYyoUbo"
   },
   "source": [
    "# 3.\n",
    "### input size를 알기 위해서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQee8cNioUjL"
   },
   "outputs": [],
   "source": [
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDVGW05NoUri"
   },
   "source": [
    "# 4. \n",
    "### model 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hn6FU1proUxO"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "  def __init__(self): \n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # input_channels = 1, out_channels = 10, kernel size = 5, stribe = 1, padding= 0\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # input_channels = 10, out_channels = 20, kernel size = 5, stribe = 1, padding= 0\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False)\n",
    "        self.mp = nn.MaxPool2d(2) \n",
    "        self.fc1 = nn.Linear(320,100) #in_features=320, out_features=100, bias=True\n",
    "        self.fc2 = nn.Linear(100,10) \n",
    "\n",
    "  def forward(self, x):\n",
    "        x = F.relu(self.mp(self.conv1(x))) \n",
    "        x = F.relu(self.mp(self.conv2(x))) \n",
    "        x = self.drop2D(x)\n",
    "        x = x.view(x.size(0), -1) #view(x.size(0),-1)을 해주는 이유: linear layer에 넣어주기 위해서는 shape 변형을 해줘야하기 때문\n",
    "        x = self.fc1(x) \n",
    "        x = self.fc2(x) \n",
    "        return F.log_softmax(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccwsHldkoU3w"
   },
   "source": [
    "# 5.\n",
    "### define a loss function, select optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN9BQMZJoU8b"
   },
   "outputs": [],
   "source": [
    "model = ConvNet().to(device) \n",
    "criterion = nn.CrossEntropyLoss().to(device) # 다중분류를 위해 손실함수로는 crossentropy를 사용해준다\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35KJ9PP9oVCI"
   },
   "source": [
    "# 6.\n",
    "### train data로 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aJMrF54oVGV"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs): \n",
    "    avg_cost = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        # 모든 model의 gradient 값을 0으로 설정 - 초기화 이유 : 학습을 할 때마다 gradient를 더해줘야하기 때문에 학습이 끝나면\n",
    "        # 0으로 초기화 해줘야한다. \n",
    "        hypothesis = model(data)\n",
    "        cost = criterion(hypothesis, target) \n",
    "        cost.backward()\n",
    "        #gradient를 계산할수있는 자동 미분 기능이다. 계산된 gradient는 자동 축적된다\n",
    "        optimizer.step()\n",
    "        #계산된 gradient를 바탕으로 파라미터를 업데이트 해준다 \n",
    "        avg_cost += cost / len(train_loader) \n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bxJSYFToVLy"
   },
   "source": [
    "# 7. \n",
    "\n",
    "### test 데이터로 accuracy 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yzDsZ9roVQM"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#model.eval : evaluation과정에서 사용하지 않을 layer들의 전원을 끈다.\n",
    "with torch.no_grad(): \n",
    "    #no_grad 사용 이유: test데이터에 데에서는 backprogation을 진행하지 않으므로 자동으로 gradient를 트래킹하지 않도록 하는 것\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(data)\n",
    "        preds = torch.max(out.data, 1)[1] \n",
    "        #torch.max(out.data)를 하면 최대값, 최대값의 위치가 두개가 나오는데 거기서 최대값의 위치만 사용하기 위해 [1]을 해준다\n",
    "        total += len(target) \n",
    "        correct += (preds==target).sum().item() \n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Framework_PyTorch.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
